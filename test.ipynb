{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing of Requirements (only run this if you haven't installed the necessary libraries found in requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as  gpd\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo\n",
    "- convert all geojson files into 1 geodataframe \n",
    "- data cleaning\n",
    "- clip the inputs onto the map layer, similar to getting the intersection between the points and the map layer\n",
    "- return the output onto a file\n",
    "- write documentation in this notebook if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Paranaque Images and Saving a compiled GEOJSON file of the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the data of Paranque images\n",
    "paranaque_json_dir = 'data/paranaque'\n",
    "\n",
    "os.chdir(paranaque_json_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_list = []\n",
    "geojson_Count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir():\n",
    "    if file.endswith('.geojson'):\n",
    "        gdf = gpd.read_file(file)\n",
    "        geojson_Count += 1\n",
    "        \n",
    "        # filter out null json files\n",
    "        if '\"features\": []' not in gdf:\n",
    "            gdf = gpd.read_file(file)\n",
    "            gdf_list.append(gdf)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this if you want to view the compiled json\n",
    "\n",
    "# gdf_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the compiled images into a GeoDataFrame in a GEOJSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = 'output_geojson'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# merged_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True), crs=gdf_list[0].crs)\n",
    "# output_filename = 'output_geojson/merged_paranaque.geojson'\n",
    "# merged_gdf.to_file(output_filename, driver='GeoJSON')\n",
    "# print(f\"Saved {output_filename}\")\n",
    "\n",
    "#the file is found in a folder that can be viewed in the data/paranaque folder as \"output_geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install imagehash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# from PIL import Image\n",
    "# import imagehash\n",
    "\n",
    "# def hash_image(file_path):\n",
    "#     \"\"\"\n",
    "#     Compute a hash for an image file.\n",
    "#     \"\"\"\n",
    "#     with Image.open(file_path) as img:\n",
    "#         return imagehash.average_hash(img)\n",
    "\n",
    "# def filter_similar_images(gdf_list):\n",
    "#     \"\"\"\n",
    "#     Filter out similar images based on their hash.\n",
    "#     \"\"\"\n",
    "#     filtered_gdf_list = []\n",
    "#     hash_set = set()\n",
    "\n",
    "#     for gdf in gdf_list:\n",
    "#         file_path = gdf['thumb_2048_url']  # Replace 'your_image_column' with the column containing image file paths\n",
    "#         file_hash = hash_image(file_path)\n",
    "\n",
    "#         if file_hash not in hash_set:\n",
    "#             hash_set.add(file_hash)\n",
    "#             filtered_gdf_list.append(gdf)\n",
    "\n",
    "#     return filtered_gdf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for setting up model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for checking similarity score of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sean\\\\Documents\\\\Python Notebooks\\\\street-image-extractor'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img1</th>\n",
       "      <th>img2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  img1  \\\n",
       "0    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "1    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "2    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "3    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "4    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "..                                                 ...   \n",
       "133  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "134  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "135  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "136  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "137  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "\n",
       "                                                  img2  label  \n",
       "0    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "1    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "2    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "3    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "4    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "..                                                 ...    ...  \n",
       "133  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      0  \n",
       "134  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      0  \n",
       "135  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "136  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "137  https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df = pd.read_csv(\"train.csv\")\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_gdf_list = filter_similar_images(gdf_list)\n",
    "\n",
    "# output_dir = 'output_geojson'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# merged_gdf = gpd.GeoDataFrame(pd.concat(filtered_gdf_list, ignore_index=True), crs=filtered_gdf_list[0].crs)\n",
    "# output_filename = 'output_geojson/merged_paranaque.geojson'\n",
    "# merged_gdf.to_file(output_filename, driver='GeoJSON')\n",
    "# print(f\"Saved {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW MODEL ATTEMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Function to create the base convolutional neural network (CNN) for image embedding\n",
    "def create_base_network(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(input_layer)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Function to calculate the Euclidean distance between two image embeddings\n",
    "def euclidean_distance(vectors):\n",
    "    vector1, vector2 = vectors\n",
    "    sum_squared = K.sum(K.square(vector1 - vector2), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "# Function to create the Siamese network\n",
    "def create_siamese_network(input_shape):\n",
    "    input_image1 = Input(shape=input_shape)\n",
    "    input_image2 = Input(shape=input_shape)\n",
    "\n",
    "    base_network = create_base_network(input_shape)\n",
    "\n",
    "    # Getting the encoded representation of the input images\n",
    "    encoded_image1 = base_network(input_image1)\n",
    "    encoded_image2 = base_network(input_image2)\n",
    "\n",
    "    # Calculating the distance between the encoded representations\n",
    "    distance = Lambda(euclidean_distance)([encoded_image1, encoded_image2])\n",
    "\n",
    "    # Creating the Siamese model\n",
    "    siamese_model = Model(inputs=[input_image1, input_image2], outputs=distance)\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img1</th>\n",
       "      <th>img2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  img1  \\\n",
       "0    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "1    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "2    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "3    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "4    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...   \n",
       "..                                                 ...   \n",
       "232  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...   \n",
       "233  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...   \n",
       "234  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...   \n",
       "235  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...   \n",
       "236  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...   \n",
       "\n",
       "                                                  img2  label  \n",
       "0    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "1    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "2    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "3    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "4    https://scontent.fmnl30-2.fna.fbcdn.net/m1/v/t...      1  \n",
       "..                                                 ...    ...  \n",
       "232  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...      1  \n",
       "233  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...      1  \n",
       "234  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...      1  \n",
       "235  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...      1  \n",
       "236  https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t...      1  \n",
       "\n",
       "[237 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df = pd.read_csv(\"train.csv\")\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from io import BytesIO\n",
    "\n",
    "# Define the model\n",
    "def build_siamese_network(input_shape):\n",
    "    left_input = layers.Input(shape=input_shape)\n",
    "    right_input = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Shared convolutional layers\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "    # Encoding for both left and right inputs\n",
    "    encoded_left = model(left_input)\n",
    "    encoded_right = model(right_input)\n",
    "\n",
    "    # L1 distance layer between the two encoded representations\n",
    "    L1_layer = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))\n",
    "\n",
    "    # Add the distance layer to the network\n",
    "    L1_distance = L1_layer([encoded_left, encoded_right])\n",
    "\n",
    "    # Prediction layer\n",
    "    prediction = layers.Dense(1, activation='sigmoid')(L1_distance)\n",
    "\n",
    "    # Create and compile the model\n",
    "    siamese_model = models.Model(inputs=[left_input, right_input], outputs=prediction)\n",
    "    siamese_model.compile(loss=BinaryCrossentropy(), optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "def preprocess_image_from_url(image_url, target_size):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    img_array = tf.cast(img_array, tf.float32) / 255.0  # Normalize pixel values to be between 0 and 1\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (237 , 237 , 3)  # Adjust input shape based on your images\n",
    "target_size = (237 , 237 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = np.array([preprocess_image_from_url(row, target_size) for row in img_df['img1'].tolist()])\n",
    "img2 = np.array([preprocess_image_from_url(row, target_size) for row in img_df['img2'].tolist()])\n",
    "\n",
    "labels = np.array(img_df['label'].tolist())\n",
    "\n",
    "img1 = img1.reshape((-1,) + img1.shape[2:])\n",
    "img2 = img2.reshape((-1,) + img2.shape[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)       [(None, 237, 237, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)       [(None, 237, 237, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)   (None, 128)                  2663532   ['input_20[0][0]',            \n",
      "                                                          8          'input_21[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)           (None, 128)                  0         ['sequential_5[0][0]',        \n",
      "                                                                     'sequential_5[1][0]']        \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 1)                    129       ['lambda_8[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26635457 (101.61 MB)\n",
      "Trainable params: 26635457 (101.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 652ms/step - loss: 0.5517 - accuracy: 0.5274\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 0.3654 - accuracy: 0.7468\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 5s 614ms/step - loss: 0.2322 - accuracy: 0.9789\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 5s 631ms/step - loss: 0.1438 - accuracy: 0.9873\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 0.0887 - accuracy: 0.9916\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 5s 628ms/step - loss: 0.0552 - accuracy: 0.9916\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 5s 626ms/step - loss: 0.0364 - accuracy: 0.9916\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 5s 649ms/step - loss: 0.0257 - accuracy: 0.9916\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 0.0197 - accuracy: 0.9916\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 5s 646ms/step - loss: 0.0159 - accuracy: 0.9916\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 5s 628ms/step - loss: 0.0140 - accuracy: 0.9916\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 5s 627ms/step - loss: 0.0125 - accuracy: 0.9916\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.0117 - accuracy: 0.9916\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 5s 651ms/step - loss: 0.0111 - accuracy: 0.9916\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.0107 - accuracy: 0.9916\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 5s 641ms/step - loss: 0.0104 - accuracy: 0.9916\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 5s 645ms/step - loss: 0.0102 - accuracy: 0.9916\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 5s 643ms/step - loss: 0.0100 - accuracy: 0.9916\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 0.0098 - accuracy: 0.9916\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 5s 645ms/step - loss: 0.0097 - accuracy: 0.9916\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.0096 - accuracy: 0.9916\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.0095 - accuracy: 0.9916\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.0094 - accuracy: 0.9916\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 5s 626ms/step - loss: 0.0094 - accuracy: 0.9916\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 5s 627ms/step - loss: 0.0093 - accuracy: 0.9916\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 5s 642ms/step - loss: 0.0092 - accuracy: 0.9916\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 5s 661ms/step - loss: 0.0092 - accuracy: 0.9916\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 6s 742ms/step - loss: 0.0092 - accuracy: 0.9916\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 5s 638ms/step - loss: 0.0091 - accuracy: 0.9916\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.0091 - accuracy: 0.9916\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 5s 657ms/step - loss: 0.0091 - accuracy: 0.9916\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 5s 683ms/step - loss: 0.0090 - accuracy: 0.9916\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 5s 633ms/step - loss: 0.0090 - accuracy: 0.9916\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 5s 643ms/step - loss: 0.0090 - accuracy: 0.9916\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 5s 628ms/step - loss: 0.0090 - accuracy: 0.9916\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 5s 636ms/step - loss: 0.0090 - accuracy: 0.9916\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 5s 644ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 5s 620ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 5s 630ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 5s 650ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 5s 630ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 5s 632ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 5s 646ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 0.0088 - accuracy: 0.9916\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 5s 655ms/step - loss: 0.0088 - accuracy: 0.9916\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.0088 - accuracy: 0.9916\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 5s 630ms/step - loss: 0.0088 - accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19664398790>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "siamese_model = build_siamese_network(input_shape)\n",
    "\n",
    "# siamese_model = create_siamese_network(input_shape)\n",
    "siamese_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "siamese_model.summary()\n",
    "\n",
    "\n",
    "# Training the Siamese network with your image pairs and similarity scores\n",
    "# X_train_image1, X_train_image2 are the image pairs, and y_train is the similarity score (1 or 0)\n",
    "siamese_model.fit([img1, img2], labels, epochs=50, batch_size=32)\n",
    "\n",
    "# After training, you can use the model to predict the similarity between two new images\n",
    "# similarity_score = siamese_model.predict([image1, image2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.21223594\n",
      "The images are dissimilar.\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a trained Siamese model named 'siamese_model'\n",
    "\n",
    "# Load and preprocess two new images from URLs\n",
    "new_image1_url = \"https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t6/An9p5poMGx43oI2-KIdMOBb2EVLa--84-2kdezmRT5F7Wge0ZaCKsYu6fCzA96HaWjiYNZB_Kpy-3Jz1OYpnb-G-1ZpI91XJuilqNReu0Zp7quBBf_c4U34OcY_woufUSc66LXv5DVWjG1UoDks_lQ?stp=s2048x1152&ccb=10-5&oh=00_AfBJEHFmkp-Ri2eXF_Q6HJm3gNzbQhvrVAf7Dsi566DksQ&oe=65CEC55A&_nc_sid=201bca\"\n",
    "new_image2_url = \"https://scontent.fmnl17-5.fna.fbcdn.net/m1/v/t6/An_LF2eubR5Wlwzl_ODdgppINVi5OZYDQLP5lPZZZ_Qs6go4pOdbXf3X6dP7KOKbPqjfWohcNmyonaByk5lRrg1Q0AXK3tegqET81QF9ID3gMoIqpt3s54eL7QdPs2NI_N3DEgHaE5pBKA5OlR6Oloc?stp=s2048x1152&ccb=10-5&oh=00_AfD3ZD_dGPj-gpe1U665FQPOPJUSGTzcHmoM_zkwS4Zjug&oe=65CEE44C&_nc_sid=201bca\"\n",
    "\n",
    "new_image1 = preprocess_image_from_url(new_image1_url, target_size)\n",
    "new_image2 = preprocess_image_from_url(new_image2_url, target_size)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = siamese_model.predict([new_image1, new_image2])\n",
    "\n",
    "# Interpret the predictions\n",
    "similarity_probability = predictions[0][0]\n",
    "\n",
    "print(similarity_probability)\n",
    "\n",
    "# # Threshold for similarity (you can adjust this based on your needs)\n",
    "similarity_threshold = 0.40\n",
    "\n",
    "if similarity_probability >= similarity_threshold:\n",
    "    print(\"The images are similar.\")\n",
    "else:\n",
    "    print(\"The images are dissimilar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
